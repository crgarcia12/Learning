{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\gitrepos\\github\\crgarcia12\\learning\\embeddings\\.venv\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: azure-search-documents in c:\\gitrepos\\github\\crgarcia12\\learning\\embeddings\\.venv\\lib\\site-packages (11.4.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in c:\\gitrepos\\github\\crgarcia12\\learning\\embeddings\\.venv\\lib\\site-packages (from azure-search-documents) (1.30.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\gitrepos\\github\\crgarcia12\\learning\\embeddings\\.venv\\lib\\site-packages (from azure-search-documents) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\gitrepos\\github\\crgarcia12\\learning\\embeddings\\.venv\\lib\\site-packages (from azure-search-documents) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\gitrepos\\github\\crgarcia12\\learning\\embeddings\\.venv\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-search-documents) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\gitrepos\\github\\crgarcia12\\learning\\embeddings\\.venv\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-search-documents) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\gitrepos\\github\\crgarcia12\\learning\\embeddings\\.venv\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-search-documents) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\gitrepos\\github\\crgarcia12\\learning\\embeddings\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-search-documents) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\gitrepos\\github\\crgarcia12\\learning\\embeddings\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-search-documents) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\gitrepos\\github\\crgarcia12\\learning\\embeddings\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-search-documents) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\gitrepos\\github\\crgarcia12\\learning\\embeddings\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-search-documents) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install azure-search-documents\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import os\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the variables\n",
    "openai_endpoint = os.environ.get('OPENAI_ENDPOINT')\n",
    "openai_key = os.environ.get('OPENAI_KEY')\n",
    "aisearch_endpoint = os.environ.get('AISEARCH_ENDPOINT')\n",
    "aisearch_key = os.environ.get('AISEARCH_KEY')\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "  api_key = openai_key,\n",
    "  api_version = \"2024-02-01\",\n",
    "  azure_endpoint = openai_endpoint\n",
    ")\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai_client.embeddings.create(input = [text], model=model).data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document uploaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "  api_key = openai_key,\n",
    "  api_version = \"2024-02-01\",\n",
    "  azure_endpoint = openai_endpoint\n",
    ")\n",
    "\n",
    "# Set up the connection\n",
    "credential = AzureKeyCredential(aisearch_key)\n",
    "client = SearchClient(endpoint=aisearch_endpoint, index_name='enterprise_docs', credential=credential)\n",
    "\n",
    "documents = json.loads(open('documents.json').read())\n",
    "\n",
    "for document in documents:\n",
    "    document['embedding'] = get_embedding(document['content'])\n",
    "    client.upload_documents(documents=[document])\n",
    "\n",
    "print('Document uploaded successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Define the query\n",
    "def find_documents(text):\n",
    "    query = {\n",
    "        \"vectorQueries\": [\n",
    "            {\n",
    "            \"kind\": \"text\",\n",
    "            \"text\": text,\n",
    "            \"k\": 2,\n",
    "            \"fields\": \"embedding\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Perform the search\n",
    "    response = client.search(query)\n",
    "\n",
    "    # Convert the response to a list of dictionaries\n",
    "    documents = [{'title': doc['title'], 'content': doc['content']} for doc in response]\n",
    "    return str(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "def call_gpt(question):\n",
    "  #question = \"Do our Indian Pale Ale have Tomatoes?\"\n",
    "  documents = find_documents(question)\n",
    "\n",
    "  # Print the documents variable in a pretty format\n",
    "  print('-------------DOCUMENTS-------------')\n",
    "  pprint(documents)\n",
    "  print('-----------------')\n",
    "\n",
    "  system_prompt = '''\n",
    "  You are a helpful assistant working at a beer factory.\n",
    "  YOU WILL ONLY ANSWER BASED ON THE 'DOCUMENTS' IN THE PROMPT.\n",
    "  If the information is not in the documents, you answer with: Sorry, I dont know.\n",
    "  Dont output the documents, only the answer.\n",
    "  Respond very politely and friendly.\n",
    "  DOCUMENTS: ''' + documents \n",
    "\n",
    "  response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "          {\"role\": \"system\", \"content\": system_prompt},\n",
    "          {\"role\": \"user\", \"content\": question}\n",
    "      ]\n",
    "  )\n",
    "\n",
    "  #print(response.model_dump_json(indent=2))\n",
    "  print('-------------RESPONSE-------------')\n",
    "  print(response.choices[0].message.content)\n",
    "  print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------DOCUMENTS-------------\n",
      "'[]'\n",
      "-----------------\n",
      "-------------RESPONSE-------------\n",
      "Sorry, I don't know.\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "call_gpt(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
